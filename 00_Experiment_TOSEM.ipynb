{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment to check discoverability, conformance of different models\n",
    "\n",
    "We run the following experiment with different random initial Models $M$:\n",
    "\n",
    "1. Generate random model $M$\n",
    "2. Simulate a log of 100k traces $L$ of model $M$\n",
    "3. For $i$ in $[1,3,10,30,100,300,...,100000]$, use a growing subset $L'_i$ of $L$ with $|L'_i| = i$\n",
    "4. Discover a model $M_d$ from $L'_{i}$ with an algorithm of your choice\n",
    "5. Report precision and recall for:\n",
    "  * $M$ vs. $L'_i$\n",
    "  * $L'_i$ vs. $M_d$\n",
    "  * $M$ vs. $M_d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare classpath with maven repository, maven local, and some more jars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%maven dk.brics:automaton:1.12-1\n",
    "%maven commons-logging:commons-logging:1.2\n",
    "%maven org.apache.commons:commons-collections4:4.1\n",
    "%maven org.apache.commons:commons-lang3:3.7\n",
    "%maven org.apache.commons:commons-math3:3.6.1\n",
    "%maven colt:colt:1.2.0\n",
    "%maven jgraph:jgraph:5.13.0.0\n",
    "%maven net.sf.trove4j:trove4j:3.0.3\n",
    "%maven org.simpleframework:simple-xml:2.7.1\n",
    "%maven io.github.andreas-solti.matrix-toolkits-java:mtj:1.0.8\n",
    "%maven net.sourceforge.f2j:arpack_combined_all:0.1\n",
    "%maven com.github.fommil.netlib:all:1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%loadFromPOM\n",
    "<repository>\n",
    "    <id>openxes-repo</id>\n",
    "    <url>file:////home/prom/openxes</url>\n",
    "</repository>\n",
    "\n",
    "<!-- Not available on Maven, local copy -->\n",
    "<dependency>\n",
    "    <groupId>org.deckfour</groupId>\n",
    "    <artifactId>openxes</artifactId>\n",
    "    <version>2.16</version>\n",
    "</dependency>\n",
    "\n",
    "<dependency>\n",
    "    <groupId>io.github.andreas-solti.xeslite</groupId>\n",
    "    <artifactId>xeslite</artifactId>\n",
    "    <version>0.0.1</version>\n",
    "</dependency>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "List<String> addedJars = %jars /home/prom/lib/plugins/*.jar\n",
    "List<String> addedJars2 = %jars /home/prom/lib/*.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[/home/prom/lib/plugins/StochasticPetriNets.jar, /home/prom/lib/plugins/OpenXES.jar, /home/prom/lib/plugins/AntiAlignments.jar, /home/prom/lib/plugins/EfficientStorage.jar, /home/prom/lib/plugins/Properties.jar, /home/prom/lib/plugins/PTConversions.jar, /home/prom/lib/plugins/ProM-Models.jar, /home/prom/lib/plugins/XESStandard.jar, /home/prom/lib/plugins/AcceptingPetriNet.jar, /home/prom/lib/plugins/Widgets.jar, /home/prom/lib/plugins/ProM-Framework.jar, /home/prom/lib/plugins/PetriNets.jar, /home/prom/lib/plugins/openxes-2.16.jar, /home/prom/lib/plugins/ProjectedRecallAndPrecision.jar, /home/prom/lib/plugins/ProM-Contexts.jar, /home/prom/lib/plugins/ProcessTree.jar, /home/prom/lib/plugins/InductiveMiner.jar, /home/prom/lib/plugins/EvolutionaryTreeMiner.jar, /home/prom/lib/plugins/ProM-Plugins.jar, /home/prom/lib/plugins/PNetReplayer.jar]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addedJars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.stream.IntStream;\n",
    "import org.deckfour.xes.info.XLogInfo;\n",
    "import org.deckfour.xes.info.impl.XLogInfoImpl;\n",
    "import org.deckfour.xes.info.XLogInfoFactory;\n",
    "import org.deckfour.xes.model.XLog;\n",
    "import org.deckfour.xes.classification.XEventClassifier;\n",
    "import org.deckfour.xes.classification.XEventClasses;\n",
    "\n",
    "import org.processmining.acceptingpetrinet.models.AcceptingPetriNet;\n",
    "import org.processmining.acceptingpetrinet.models.impl.AcceptingPetriNetImpl;\n",
    "import org.processmining.eigenvalue.Utils;\n",
    "import org.processmining.eigenvalue.automata.PrecisionRecallComputer;\n",
    "import org.processmining.eigenvalue.data.EntropyPrecisionRecall;\n",
    "import org.processmining.eigenvalue.generator.GenerateLogAndModel;\n",
    "import org.processmining.eigenvalue.generator.NAryTreeGenerator;\n",
    "import org.processmining.eigenvalue.tree.TreeUtils;\n",
    "import org.apache.commons.lang3.tuple.MutablePair;\n",
    "import org.apache.commons.lang3.tuple.Pair;\n",
    "import org.processmining.plugins.etm.model.narytree.NAryTree;\n",
    "import org.processmining.plugins.stochasticpetrinet.StochasticNetUtils;\n",
    "\n",
    "import org.processmining.projectedrecallandprecision.helperclasses.ProjectPetriNetOntoActivities;\n",
    "import org.processmining.projectedrecallandprecision.helperclasses.AcceptingPetriNet2automaton;\n",
    "import org.processmining.projectedrecallandprecision.helperclasses.AutomatonFailedException;\n",
    "import org.processmining.projectedrecallandprecision.helperclasses.EfficientLog;\n",
    "import com.google.common.base.Stopwatch;\n",
    "\n",
    "import org.processmining.eigenvalue.test.TestUtils;\n",
    "\n",
    "import dk.brics.automaton2.Automaton;\n",
    "import org.processmining.plugins.etm.model.narytree.conversion.NAryTreeToProcessTree;\n",
    "import org.processmining.processtree.ProcessTree;\n",
    "import org.processmining.ptconversions.pn.ProcessTree2Petrinet;\n",
    "import org.processmining.ptconversions.pn.ProcessTree2Petrinet.NotYetImplementedException;\n",
    "import org.processmining.ptconversions.pn.ProcessTree2Petrinet.InvalidProcessTreeException;\n",
    "\n",
    "import org.processmining.plugins.InductiveMiner.efficienttree.EfficientTree;\n",
    "import org.processmining.plugins.InductiveMiner.efficienttree.EfficientTree2processTree;\n",
    "import org.processmining.plugins.InductiveMiner.mining.MiningParameters;\n",
    "import org.processmining.plugins.inductiveminer2.mining.InductiveMiner;\n",
    "import org.processmining.plugins.inductiveminer2.variants.MiningParametersIMInfrequent;\n",
    "import org.processmining.plugins.InductiveMiner.mining.logs.LifeCycleClassifier;\n",
    "import org.processmining.framework.packages.PackageManager;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Experiment PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "String OUTPUT_FOLDER = \"output\"; // the results will be put here\n",
    "int NUM_ACTIVITIES = 15; // how big shall the model be?\n",
    "\n",
    "int EXPERIMENT_RUNS = 30; // number of repetitions of the experiment with different random seeded models\n",
    "int[] sublogSizes = new int[]{1,3,10,30,100,300,1000,3000,10000,30000,100000}; // gradual increments in log size following a rough exponential pattern for plotting\n",
    "\n",
    "float INDUCTIVE_MINER_THRESHOLD = 0.2f; // the default parameter for the inductive miner (infrequent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. and 2. Generate random model $M$ and simulate log $L$\n",
    "The random seed of the log generation is set to 1 by default. This way, the log will be the same if GenerateLogAndModel is used twice with the same model tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "public static final XEventClassifier CLASSIFIER = XLogInfoImpl.NAME_CLASSIFIER;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "public Pair<XLog, NAryTree> generate(int traces, int activities, NAryTreeGenerator generator, long seed){\n",
    "    generator.setSeed(seed);\n",
    "    NAryTree tree = generator.generate(activities);\n",
    "\n",
    "    XLog newLog = GenerateLogAndModel.generateLog(tree,traces);\n",
    "    return new MutablePair<>(newLog, tree);\n",
    "}\n",
    "public Pair<XLog, NAryTree> generate(int traces, int activities, long seed){\n",
    "    NAryTreeGenerator generator = new NAryTreeGenerator();\n",
    "    return generate(traces, activities, generator, seed);\n",
    "}\n",
    "public Pair<XLog, NAryTree> generate(int traces, int activities){\n",
    "    return generate(traces, activities, 42l);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oddly, this next line fails at first run... <br> At second try, however, it succeeds o_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAryTreeGenerator generator = new NAryTreeGenerator();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Helper method to compute the entropy-based precision/recall measures between two models\n",
    " */\n",
    "public EntropyPrecisionRecall getPrecisionAndRecall(AcceptingPetriNet firstNet, AcceptingPetriNet secondNet){\n",
    "    String name1 = Utils.getName(firstNet.getNet(),\"Md\");\n",
    "    String name2 = Utils.getName(secondNet.getNet(),\"M\");\n",
    "\n",
    "    String[] names = PrecisionRecallComputer.getTransitionNames(firstNet, new String[]{});\n",
    "    names = PrecisionRecallComputer.getTransitionNames(secondNet, names);\n",
    "\n",
    "    Automaton a1 = getAutomaton(firstNet, names);\n",
    "    Automaton a2 = getAutomaton(secondNet, names);\n",
    "\n",
    "    Automaton a12 = a1.intersection(a2, Utils.NOT_CANCELLER);\n",
    "\n",
    "    return PrecisionRecallComputer.getPrecisionAndRecall(a1, name1, a2, name2, a12, \"MdM\", a12.getNumberOfStates() / (double)a1.getNumberOfStates(), Utils.NOT_CANCELLER);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "/**\n",
    " * Converts a @{@link AcceptingPetriNet} to an @{@link Automaton}.\n",
    " * @param net {@link AcceptingPetriNet} to convert.\n",
    " * @param activities {@link String}[] array that captures the names in the other part, if names should be converted.\n",
    " * @return Automaton the automaton of the model projected onto the\n",
    " */\n",
    "public Automaton getAutomaton(AcceptingPetriNet net, String[] activities){\n",
    "    String[] names = PrecisionRecallComputer.getTransitionNames(net, activities);\n",
    "    System.out.println(\"\"+names);\n",
    "    AcceptingPetriNet projectedNet = ProjectPetriNetOntoActivities.project(net, Utils.NOT_CANCELLER, names);\n",
    "    Automaton a = null;\n",
    "    try {\n",
    "        a = AcceptingPetriNet2automaton.convert(projectedNet, Integer.MAX_VALUE, Utils.NOT_CANCELLER);\n",
    "    } catch (AutomatonFailedException e){\n",
    "        e.printStackTrace();\n",
    "        System.out.println(\"Error getting Automaton!\");\n",
    "    }\n",
    "    return a;\n",
    "}\n",
    "\n",
    "public Automaton getAutomaton(AcceptingPetriNet net){\n",
    "    return getAutomaton(net, new String[]{});\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "public ProcessTree mineTree(XLog xLog, float noiseThreshold){\n",
    "    XEventClassifier classifier = MiningParameters.getDefaultClassifier();\n",
    "    org.processmining.plugins.inductiveminer2.logs.IMLog log = new org.processmining.plugins.inductiveminer2.logs.IMLogImpl(xLog, classifier, new LifeCycleClassifier());\n",
    "    MiningParametersIMInfrequent miningParameters = new MiningParametersIMInfrequent();\n",
    "    miningParameters.setDebug(false);\n",
    "    EfficientTree eTree = InductiveMiner.mineEfficientTree(log, miningParameters, new PackageManager.Canceller() {\n",
    "        @Override\n",
    "        public boolean isCancelled() {\n",
    "            return false;\n",
    "        }\n",
    "    });\n",
    "\n",
    "    return EfficientTree2processTree.convert(eTree);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Select growing number of traces from the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "public AcceptingPetriNet convertProcessTreeToNet(ProcessTree processTree, int numActivities) {\n",
    "    try{\n",
    "        XEventClasses eventClasses = TestUtils.getxEventClasses(CLASSIFIER, numActivities);\n",
    "        \n",
    "        ProcessTree2Petrinet.PetrinetWithMarkings petrinetWithMarkings = ProcessTree2Petrinet.convert(processTree, true);\n",
    "        AcceptingPetriNet acceptingPetriNet = new AcceptingPetriNetImpl(petrinetWithMarkings.petrinet, petrinetWithMarkings.initialMarking, petrinetWithMarkings.finalMarking);\n",
    "        return acceptingPetriNet;\n",
    "    } catch (NotYetImplementedException | InvalidProcessTreeException e){\n",
    "        e.printStackTrace();\n",
    "        System.err.println(\"Error!\");\n",
    "        return null;\n",
    "    }\n",
    "}\n",
    "\n",
    "public AcceptingPetriNet convertToNet(NAryTree tree){\n",
    "    int numActivities = tree.numLeafs();\n",
    "    XEventClasses eventClasses = TestUtils.getxEventClasses(CLASSIFIER, numActivities);\n",
    "    ProcessTree processTree = NAryTreeToProcessTree.convert(tree, eventClasses);\n",
    "    return convertProcessTreeToNet(processTree, numActivities);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try loading a model from pnml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.simpleframework.xml.Serializer;\n",
    "import org.simpleframework.xml.core.Persister;\n",
    "import org.processmining.plugins.pnml.simple.PNMLRoot;\n",
    "import org.processmining.plugins.pnml.importing.StochasticNetDeserializer;\n",
    "import java.io.FileInputStream;\n",
    "import java.io.FileNotFoundException;\n",
    "import org.processmining.projectedrecallandprecision.helperclasses.ProjectPetriNetOntoActivities;\n",
    "import org.processmining.models.graphbased.directed.petrinet.StochasticNet;\n",
    "import org.processmining.models.semantics.petrinet.Marking;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "public Automaton openNetAsAutomaton(String filename) throws Exception{\n",
    "    File file = new File(filename);\n",
    "    Serializer serializer = new Persister();\n",
    "    PNMLRoot pnml = serializer.read(PNMLRoot.class, new FileInputStream(file));\n",
    "\n",
    "    StochasticNetDeserializer converter = new StochasticNetDeserializer();\n",
    "    Object[] result = converter.convertToNet(null, pnml, filename, false);\n",
    "    \n",
    "    StochasticNet sNet = (StochasticNet) result[0];\n",
    "    Marking initMarking = (Marking) result[1];\n",
    "    AcceptingPetriNet acceptingPetriNet = new AcceptingPetriNetImpl(sNet, initMarking, StochasticNetUtils.getFinalMarking(null, sNet));\n",
    "    \n",
    "    return PrecisionRecallComputer.getAutomaton(acceptingPetriNet);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming race enabling memory for net noID imported from (./data/Figure5.pnml)\n",
      "Assuming 'minutes' as the time unit in net noID imported from (./data/Figure5.pnml)\n",
      "[Ljava.lang.String;@47d87bb8\n"
     ]
    }
   ],
   "source": [
    "String filename = \"./data/Figure5.pnml\";\n",
    "Automaton autom = openNetAsAutomaton(filename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "digraph Automaton {\n",
       "  rankdir = LR;\n",
       "  0 [shape=circle,label=\"\"];\n",
       "  initial [shape=plaintext,label=\"\"];\n",
       "  initial -> 0\n",
       "  0 -> 1 [label=\"\\u0005\"]\n",
       "  1 [shape=circle,label=\"\"];\n",
       "  1 -> 2 [label=\"\\u0004\"]\n",
       "  1 -> 3 [label=\"\\u0000\"]\n",
       "  2 [shape=circle,label=\"\"];\n",
       "  2 -> 2 [label=\"\\u0003\"]\n",
       "  2 -> 4 [label=\"\\u0002\"]\n",
       "  2 -> 2 [label=\"\\u0001\"]\n",
       "  3 [shape=doublecircle,label=\"\"];\n",
       "  4 [shape=circle,label=\"\"];\n",
       "  4 -> 3 [label=\"\\u0000\"]\n",
       "}\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autom.toDot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public static void runExperiment(int runNumber, XLog log, AcceptingPetriNet acceptingPetriNet, String outputFolder,int[] sublogSizes){\n",
    "    File outFolder = new File(outputFolder + File.separator + runNumber);\n",
    "    if (!outFolder.exists()){\n",
    "        outFolder.mkdirs();\n",
    "    }\n",
    "    \n",
    "    for (int i : sublogSizes){\n",
    "        try (BufferedWriter writer = new BufferedWriter(new FileWriter(new File(outFolder, \"exp_results_\"+i+\".csv\")))) {\n",
    "            writer.write(EntropyPrecisionRecall.getHeader()+\"\\n\");\n",
    "\n",
    "            XLog subLog = Utils.cloneLog(log, i);\n",
    "            \n",
    "            System.out.println(\"Running with log size: \"+subLog.size());\n",
    "\n",
    "            Stopwatch timer = Stopwatch.createStarted();\n",
    "            EntropyPrecisionRecall resModelLog = PrecisionRecallComputer.getPrecisionAndRecall(null, Utils.NOT_CANCELLER, subLog,  acceptingPetriNet);\n",
    "            writer.write(resModelLog.getCSVString()+\"\\n\");\n",
    "            writer.flush();\n",
    "            \n",
    "            System.out.println(\"Computing recall/precision of sublog/model took: \" + timer.stop()); timer.reset(); timer.start();\n",
    "            \n",
    "            \n",
    "            ProcessTree modelDiscovered = mineTree(subLog, INDUCTIVE_MINER_THRESHOLD); \n",
    "            System.out.println(\"Discovery of m_discov from sublog took: \" + timer.stop()); timer.reset(); timer.start();\n",
    "            \n",
    "            AcceptingPetriNet petriNetDiscovered = convertProcessTreeToNet(modelDiscovered, modelDiscovered.size());\n",
    "\n",
    "            \n",
    "            EntropyPrecisionRecall resLogDiscModel = PrecisionRecallComputer.getPrecisionAndRecall(null, Utils.NOT_CANCELLER, subLog,  petriNetDiscovered);\n",
    "            writer.write(resLogDiscModel.getCSVString()+\"\\n\");\n",
    "            \n",
    "            System.out.println(\"Computing recall/precision of sublog/m_discov: \" + timer.stop()); timer.reset(); timer.start();\n",
    "\n",
    "            EntropyPrecisionRecall resModelDiscModel = getPrecisionAndRecall(acceptingPetriNet, petriNetDiscovered);   \n",
    "            writer.write(resModelDiscModel.getCSVString()+\"\\n\");\n",
    "            System.out.println(\"Computing recall/precision of m_discov/model: \" + timer.stop()); \n",
    "\n",
    "            writer.flush();\n",
    "        } catch (IOException e) {\n",
    "            e.printStackTrace();\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "int n = 3;\n",
    "// generate Log and Model\n",
    "Pair<XLog,NAryTree> pair = generate(100000, NUM_ACTIVITIES, generator, 42+n);\n",
    "XLog log = pair.getLeft();\n",
    "NAryTree tree = pair.getRight();\n",
    "System.out.println(\"Generated log and model with sizes: \" + log.size()+\" - \"+tree.numLeafs()+\" (nodes: \"+tree.size()+\")\");\n",
    "\n",
    "// convert tree to accepting Petri net\n",
    "AcceptingPetriNet acceptingPetriNet = convertToNet(tree);\n",
    "\n",
    "String outputFolder = OUTPUT_FOLDER;\n",
    "int runNumber = n;\n",
    "\n",
    "runExperiment(n, log, acceptingPetriNet, OUTPUT_FOLDER, sublogSizes);\n",
    "/*\n",
    "File outFolder = new File(outputFolder + File.separator + runNumber);\n",
    "if (!outFolder.exists()){\n",
    "    outFolder.mkdirs();\n",
    "}\n",
    "\n",
    "for (int i : sublogSizes){\n",
    "    try (BufferedWriter writer = new BufferedWriter(new FileWriter(new File(outFolder, \"exp_results_\"+i+\".csv\")))) {\n",
    "        writer.write(EntropyPrecisionRecall.getHeader()+\"\\n\");\n",
    "\n",
    "        XLog subLog = Utils.cloneLog(log, i);\n",
    "        System.out.println(\"Running with log size: \"+subLog.size());\n",
    "\n",
    "        long time = org.utiSystem.current\n",
    "        EntropyPrecisionRecall resModelLog = PrecisionRecallComputer.getPrecisionAndRecall(null, Utils.NOT_CANCELLER, subLog,  acceptingPetriNet);\n",
    "        writer.write(resModelLog.getCSVString()+\"\\n\");\n",
    "        writer.flush();\n",
    "\n",
    "        System.out.println(\"Computed precision and recall in : \"+subLog.size());\n",
    "        \n",
    "        ProcessTree modelDiscovered = mineTree(subLog, INDUCTIVE_MINER_THRESHOLD);\n",
    "        AcceptingPetriNet petriNetDiscovered = convertProcessTreeToNet(modelDiscovered, modelDiscovered.size());\n",
    "\n",
    "        EntropyPrecisionRecall resLogDiscModel = PrecisionRecallComputer.getPrecisionAndRecall(null, Utils.NOT_CANCELLER, subLog,  petriNetDiscovered);\n",
    "        writer.write(resLogDiscModel.getCSVString()+\"\\n\");\n",
    "\n",
    "        EntropyPrecisionRecall resModelDiscModel = getPrecisionAndRecall(acceptingPetriNet, petriNetDiscovered);   \n",
    "        writer.write(resModelDiscModel.getCSVString()+\"\\n\");\n",
    "\n",
    "        writer.flush();\n",
    "    } catch (IOException e) {\n",
    "        e.printStackTrace();\n",
    "    }\n",
    "}\n",
    "*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntStream.range(0, EXPERIMENT_RUNS).forEachOrdered(n -> {\n",
    "    System.out.println(\"**** Running Experiment \"+n+\" ****\");\n",
    "    \n",
    "    // generate Log and Model\n",
    "    Pair<XLog,NAryTree> pair = generate(100000, NUM_ACTIVITIES, generator, 42+n);\n",
    "    XLog log = pair.getLeft();\n",
    "    NAryTree tree = pair.getRight();\n",
    "    System.out.println(\"Generated log and model with sizes: \" + log.size()+\" - \"+tree.numLeafs()+\" (nodes: \"+tree.size()+\")\");\n",
    "    \n",
    "    // convert tree to accepting Petri net\n",
    "    AcceptingPetriNet acceptingPetriNet = convertToNet(tree);\n",
    "    \n",
    "    // run experiment with different sublog sizes:\n",
    "    runExperiment(n, log, acceptingPetriNet, OUTPUT_FOLDER, sublogSizes);\n",
    "});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "java",
   "file_extension": ".jshell",
   "mimetype": "text/x-java-source",
   "name": "Java",
   "pygments_lexer": "java",
   "version": "11.0.3+7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
